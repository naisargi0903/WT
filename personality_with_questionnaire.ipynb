{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naisargi0903/WT/blob/main/personality_with_questionnaire.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "307QW15TTGuF"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.15.0\n",
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak_9OqlRSH07"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import TFBertModel, BertTokenizer\n",
        "seed_value = 29\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "np.set_printoptions(precision=2)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(seed_value)\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.layers as layers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import auc, roc_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YwrsfK-SeGc"
      },
      "outputs": [],
      "source": [
        "N_AXIS = 4\n",
        "MAX_SEQ_LEN = 128\n",
        "BERT_NAME = 'bert-base-uncased'\n",
        "'''\n",
        "EMOTIONAL AXES:\n",
        "Introversion (I) – Extroversion (E)\n",
        "Intuition (N) – Sensing (S)\n",
        "Thinking (T) – Feeling (F)\n",
        "Judging (J) – Perceiving (P)\n",
        "'''\n",
        "axes = [\"I-E\",\"N-S\",\"T-F\",\"J-P\"]\n",
        "classes = {\"I\":0, \"E\":1, # axis 1\n",
        "           \"N\":0,\"S\":1, # axis 2\n",
        "           \"T\":0, \"F\":1, # axis 3\n",
        "           \"J\":0,\"P\":1} # axis 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIVMwGvITYvD"
      },
      "outputs": [],
      "source": [
        "def text_preprocessing(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text.encode('ascii', 'ignore').decode('ascii')\n",
        "    if text.startswith(\"'\"):\n",
        "        text = text[1:-1]\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajt_zeqYTiOW"
      },
      "outputs": [],
      "source": [
        "train_n=6624\n",
        "val_n=1024\n",
        "test_n=1024\n",
        "data = pd.read_csv(\"/content/mbti_1.csv\")\n",
        "data = data.sample(frac=1)\n",
        "labels = []\n",
        "print(data)\n",
        "for personality in data[\"type\"]:\n",
        "    pers_vect = []\n",
        "    for p in personality:\n",
        "        pers_vect.append(classes[p])\n",
        "    labels.append(pers_vect)\n",
        "sentences = data[\"posts\"].apply(str).apply(lambda x: text_preprocessing(x))\n",
        "labels = np.array(labels, dtype=\"float32\")\n",
        "train_sentences = list(sentences[:train_n])\n",
        "y_train = labels[:train_n]\n",
        "val_sentences = list(sentences[train_n:train_n + val_n])\n",
        "y_val = labels[train_n:train_n+val_n]\n",
        "test_sentences = list(sentences[train_n + val_n:train_n + val_n + test_n])\n",
        "y_test = labels[train_n+val_n:train_n+val_n+test_n]\n",
        "y_train = labels[:train_n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcq3eAm4YHRy"
      },
      "outputs": [],
      "source": [
        "def prepare_bert_input(sentences, seq_len, bert_name):\n",
        "    # Ensure tokenizer handles the input correctly\n",
        "    tokenizer = BertTokenizer.from_pretrained(bert_name)\n",
        "\n",
        "    # No need for .tolist(), sentences is already a list\n",
        "    encodings = tokenizer(sentences, truncation=True, padding='max_length', max_length=seq_len)\n",
        "\n",
        "    # Prepare the input data for the model\n",
        "    input = [np.array(encodings[\"input_ids\"]),\n",
        "             np.array(encodings[\"attention_mask\"]),\n",
        "             np.array(encodings.get(\"token_type_ids\", np.zeros_like(encodings[\"input_ids\"])))]\n",
        "\n",
        "    return input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkImaCq8YON1"
      },
      "outputs": [],
      "source": [
        "X_train = prepare_bert_input(train_sentences, MAX_SEQ_LEN, BERT_NAME)\n",
        "X_val = prepare_bert_input(val_sentences, MAX_SEQ_LEN, BERT_NAME)\n",
        "X_test = prepare_bert_input(test_sentences, MAX_SEQ_LEN, BERT_NAME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay7dpRaBfw_y"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFBertModel, BertConfig\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "\n",
        "# Constants\n",
        "MAX_SEQ_LEN = 128  # Example value, adjust as needed\n",
        "BERT_NAME = \"bert-base-uncased\"  # Example value, adjust as needed\n",
        "N_AXIS = 4 # Example value, adjust as needed\n",
        "\n",
        "class CustomBERTModel(Model):\n",
        "    def __init__(self, bert_name, num_classes):\n",
        "        super(CustomBERTModel, self).__init__()\n",
        "        self.bert = TFBertModel.from_pretrained(bert_name)\n",
        "        self.pooling = layers.GlobalAveragePooling1D()\n",
        "        self.classifier = layers.Dense(num_classes, activation=\"sigmoid\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask, token_type_ids = inputs\n",
        "        bert_outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = self.pooling(bert_outputs.last_hidden_state)\n",
        "        return self.classifier(pooled_output)\n",
        "\n",
        "# Create the model\n",
        "model = CustomBERTModel(BERT_NAME, N_AXIS)\n",
        "\n",
        "# Define inputs\n",
        "input_ids = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name='input_ids')\n",
        "attention_mask = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name='attention_mask')\n",
        "token_type_ids = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name='token_type_ids')\n",
        "\n",
        "# Call the model with the inputs\n",
        "output = model([input_ids, attention_mask, token_type_ids])\n",
        "\n",
        "# Create the final model\n",
        "final_model = Model(inputs=[input_ids, attention_mask, token_type_ids], outputs=output)\n",
        "\n",
        "# Compile the model (optional, depends on your use case)\n",
        "final_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "final_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG3xX9NbiRn6"
      },
      "outputs": [],
      "source": [
        "max_epochs = 5\n",
        "batch_size = 32\n",
        "opt = tfa.optimizers.RectifiedAdam(learning_rate=3e-5)\n",
        "loss = keras.losses.BinaryCrossentropy()\n",
        "best_weights_file = \"weights.h5\"\n",
        "auc = keras.metrics.AUC(multi_label=True, curve=\"ROC\")\n",
        "m_ckpt = ModelCheckpoint(best_weights_file, monitor='val_'+auc.name, mode='max', verbose=2,\n",
        "                          save_weights_only=True, save_best_only=True)\n",
        "model.compile(loss=loss, optimizer=opt, metrics=[auc, keras.metrics.BinaryAccuracy()])\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=max_epochs,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[m_ckpt],\n",
        "    verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eIN9CDYnFfr"
      },
      "outputs": [],
      "source": [
        "loss = keras.losses.BinaryCrossentropy()\n",
        "best_weights_file = \"weights.h5\"\n",
        "model.load_weights(best_weights_file)\n",
        "opt = tfa.optimizers.RectifiedAdam(learning_rate=3e-5)\n",
        "model.compile(loss=loss, optimizer=opt, metrics=[keras.metrics.AUC(multi_label=True, curve=\"ROC\"),\n",
        "                                                  keras.metrics.BinaryAccuracy()])\n",
        "predictions = model.predict(X_test)\n",
        "model.evaluate(X_test, y_test, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUvXNVRmnY5I"
      },
      "outputs": [],
      "source": [
        "def plot_roc_auc(y_test, y_score, classes):\n",
        "    assert len(classes) > 1, \"len classes must be > 1\"\n",
        "    plt.figure()\n",
        "    if len(classes) > 2:  # multi-label\n",
        "        # Compute ROC curve and ROC area for each class\n",
        "        for i in range(len(classes)):\n",
        "            fpr, tpr, _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.plot(fpr, tpr, label='ROC curve of class {0} (area = {1:0.2f})'.format(classes[i], roc_auc))\n",
        "        # Compute micro-average ROC curve and ROC area\n",
        "        fpr, tpr, _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        # Plot ROC curve\n",
        "        plt.plot(fpr, tpr, label='micro-average ROC curve (area = {0:0.2f})'.format(roc_auc))\n",
        "    else:\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'.format(roc_auc))\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrFsoVVkZ7TZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define your 20 MBTI questions\n",
        "questions = [\n",
        "    \"How do you prefer to spend your free time—socializing or enjoying time alone?\",\n",
        "    \"When making decisions, do you rely more on logic or personal values?\",\n",
        "    \"Do you find it easier to focus on details or the bigger picture?\",\n",
        "    \"How comfortable are you with making decisions quickly without all the information?\",\n",
        "    \"Do you prefer planning everything out or being spontaneous?\",\n",
        "    \"How do you handle conflict—do you try to avoid it, or confront it directly?\",\n",
        "    \"Do you rely more on past experiences or new data when making decisions?\",\n",
        "    \"Do you find interacting with others energizing or draining?\",\n",
        "    \"When working on a project, do you prefer to follow instructions or come up with your own approach?\",\n",
        "    \"How often do you seek feedback from others when working on something?\",\n",
        "    \"Do you prefer a structured schedule or a more flexible approach to your day?\",\n",
        "    \"Are you more comfortable expressing your emotions or keeping them to yourself?\",\n",
        "    \"When faced with a problem, do you prefer to brainstorm ideas or research proven solutions?\",\n",
        "    \"Do you tend to focus on what’s happening right now or think ahead to the future?\",\n",
        "    \"How do you usually approach challenges—by seeking guidance or trying to figure it out on your own?\",\n",
        "    \"Do you feel more motivated by external rewards (recognition, praise) or internal satisfaction?\",\n",
        "    \"How do you deal with new information—do you analyze it carefully or trust your gut instinct?\",\n",
        "    \"Do you enjoy discussing abstract ideas or prefer to stick to practical topics?\",\n",
        "    \"When working with a team, do you prefer taking the lead or being a supportive member?\",\n",
        "    \"Do you tend to base your decisions more on logic or how they’ll affect others emotionally?\"\n",
        "]\n",
        "\n",
        "# Function to get the MBTI axis result for a given answer\n",
        "def analyze_answer(sentence, model, axes):\n",
        "    # Tokenize and prepare input for BERT\n",
        "    enc_sentences = prepare_bert_input([sentence], MAX_SEQ_LEN, BERT_NAME)\n",
        "\n",
        "    # Get predictions from the model\n",
        "    predictions = model.predict(enc_sentences)\n",
        "\n",
        "    # Convert predictions to MBTI axis values\n",
        "    pred_axis = []\n",
        "    mask = (predictions[0] > 0.5).astype(bool)\n",
        "\n",
        "    for i in range(len(mask)):\n",
        "        if mask[i]:\n",
        "            pred_axis.append(axes[i][2])  # Take second character of the axis (E, S, F, P)\n",
        "        else:\n",
        "            pred_axis.append(axes[i][0])  # Take first character of the axis (I, N, T, J)\n",
        "\n",
        "    # Return binary representation for the prediction (0 or 1)\n",
        "    return np.array([1 if mask[i] else 0 for i in range(len(mask))])\n",
        "\n",
        "# Initialize an array to hold the cumulative predictions\n",
        "total_predictions = np.zeros((N_AXIS,))\n",
        "\n",
        "# Loop through the questions and collect user responses\n",
        "for question in questions:\n",
        "    answer = input(question + \"\\n\")\n",
        "\n",
        "    # Analyze each answer and get MBTI axis prediction\n",
        "    pred = analyze_answer(answer, model, axes)\n",
        "\n",
        "    # Accumulate predictions for each axis\n",
        "    total_predictions += pred\n",
        "\n",
        "# Compute the average across all answers\n",
        "average_predictions = total_predictions / len(questions)\n",
        "\n",
        "# Determine final MBTI type based on average scores\n",
        "final_personality = []\n",
        "for i in range(len(average_predictions)):\n",
        "    if average_predictions[i] > 0.5:\n",
        "        final_personality.append(axes[i][2])  # Second character if average score > 0.5\n",
        "    else:\n",
        "        final_personality.append(axes[i][0])  # First character if average score <= 0.5\n",
        "\n",
        "# Output the final predicted MBTI personality\n",
        "print(\"\\nFinal predicted MBTI personality: \" + \"\".join(final_personality))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1KeFSp2t25S"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}